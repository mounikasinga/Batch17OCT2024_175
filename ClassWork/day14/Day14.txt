Multithreading and Parallel Programming
________________________________________
1. Parallel Programming vs. Concurrency
•	Parallel Programming: Involves executing multiple processes at the same time, typically using multiple processors or cores.
•	Concurrency: Refers to performing multiple tasks (functions) at the same time or handling multiple operations within overlapping time frames. It doesn't necessarily mean simultaneous execution but focuses on managing multiple tasks efficiently.
Key Concepts of Concurrency:
•	Responsiveness: Concurrency allows an application to remain responsive to the user even when performing long tasks in the background (e.g., web servers handling multiple client requests).
•	Multi-Core Utilization: Executes multiple instructions concurrently using multi-core processors.
•	Efficient Resource Utilization: Minimizes idle times, ensuring that system resources are optimally used.
•	Scalability: Improves the ability of the system to handle growth in tasks or users efficiently.
•	Improved Throughput: By executing tasks concurrently, particularly in I/O-bound operations, throughput is improved as CPU time isn't wasted waiting for I/O.
________________________________________
2. Methods of Handling Concurrency in Programming
1.	Multithreading:
o	Multiple threads within a single process perform different tasks concurrently.
o	Threads share the same memory space, making communication easier but requiring synchronization to avoid race conditions.
2.	Multiprocessing:
o	Separate processes handle tasks concurrently, each with its own memory space.
o	Processes are isolated from each other, which is safer, but they need Inter-Process Communication (IPC) methods like pipes or shared memory to communicate.
3.	Asynchronous Programming:
o	Involves non-blocking functions, allowing tasks like I/O operations to run without blocking the main thread, enabling other tasks to run concurrently.
o	This is commonly used in languages like Python and JavaScript.
o	Example: fork() creates a new process in multiprocessing.
________________________________________
3. Key Concepts in Multithreading
•	Atomic Operations: Allows simple, thread-safe operations without the full overhead of mutex locks.
•	Semaphores: Used to control access to shared resources by multiple threads.
Thread vs. Process
•	Similarities:
o	Both threads and processes have their own logical control flow.
o	Both can run concurrently.
o	Both are context-switched by the system.
•	Differences:
o	Threads share the same data and memory space, whereas processes have separate memory.
o	Threads are lightweight and fast to create compared to processes.
o	Threads can easily communicate because they share memory; processes need Inter-Process Communication (IPC).
o	Processes are more expensive in terms of memory and time compared to threads.
o	Threads terminate when the function finishes (via exit() or return), while processes terminate independently.
________________________________________
4. Thread Management with POSIX Threads (Pthreads)
•	Creating Threads: pthread_create()
o	Creates a new thread within the program.
o	Example: 
o	pthread_create(&thread_id, NULL, thread_function, NULL);
•	Waiting for Threads: pthread_join()
o	Waits for a specific thread to finish its execution before continuing.
o	Example: 
o	pthread_join(thread_id, NULL);
•	Getting Thread ID: pthread_self()
o	Returns the thread ID of the calling thread.
•	Terminating Threads: pthread_exit(), pthread_cancel()
o	pthread_exit() terminates the calling thread, while pthread_cancel() requests cancellation of a thread.
•	Mutexes for Synchronization: pthread_mutex_init(), pthread_mutex_lock(), pthread_mutex_unlock()
o	Used to synchronize access to shared resources to prevent race conditions.
•	Condition Variables: pthread_cond_init(), pthread_cond_wait(), pthread_cond_signal()
o	Used to synchronize threads in a way that allows threads to wait for certain conditions before proceeding.
•	Example: Thread creation and synchronization
•	pthread_mutex_t lock;
•	
•	void *my_function(void *arg) {
•	    pthread_mutex_lock(&lock); // Lock shared resource
•	    // Critical section
•	    pthread_mutex_unlock(&lock); // Unlock shared resource
•	    return NULL;
•	}
•	
•	int main() {
•	    pthread_t thread;
•	    pthread_mutex_init(&lock, NULL); // Initialize mutex
•	
•	    pthread_create(&thread, NULL, my_function, NULL);
•	    pthread_join(thread, NULL); // Wait for thread to complete
•	
•	    pthread_mutex_destroy(&lock); // Destroy mutex
•	    return 0;
•	}
•	Compilation of Pthread Programs: To compile a program using pthreads, you need to link the pthread library:
•	gcc program.c -lpthread
________________________________________
5. Key Thread Synchronization Concepts
•	Mutex Locks:
o	Mutexes are used to ensure that only one thread can access a shared resource at a time.
o	Example of mutex usage: 
o	pthread_mutex_t lock;
o	pthread_mutex_init(&lock, NULL);  // Initialize mutex
o	pthread_mutex_lock(&lock);        // Lock resource
o	// Critical section code
o	pthread_mutex_unlock(&lock);      // Unlock resource
o	pthread_mutex_destroy(&lock);     // Destroy mutex after use
•	Why Destroy Mutexes:
o	Destroying the mutex releases any resources it was using, and it's a good practice to do so when done, especially for avoiding memory leaks and errors in a larger, more complex program.
________________________________________
6. Why Do Loops Have a Semicolon?
•	Semicolon in Loops: A semicolon is used in loops like while when the loop body is empty or if the loop body is a single line of code. It allows the loop to execute without performing any operations inside it.
o	Example: 
o	while (condition);  // Empty loop body
•	Semicolon After Structures:
o	The semicolon after a structure definition is required to indicate the end of the structure definition. This is essential for correct syntax, allowing the structure to be defined as a data type that can be used later. 
o	struct Employee {
o	    int id;
o	    char name[50];
o	};  // Semicolon is mandatory after structure definition
________________________________________
7. Use of Threading in Optimizing Algorithms
•	Linear Search with Threads:
o	Threads can be used to divide a linear search into multiple smaller tasks, each handling a subset of the data, thus reducing the overall search time.
•	Mutex for Race Conditions:
o	When multiple threads access shared resources, mutexes are used to prevent race conditions by ensuring only one thread can access the shared resource at a time.

